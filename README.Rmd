---
title: "Graduate Admission"
date: 2019-05-25T20-00-00
output: 
  md_document   
---


```{r, echo = FALSE}
knitr::opts_chunk$set(
  fig.width=12, fig.height=8,
  cache = T
)
```

# Load library ------------------

```{r, warning = F, message = F}
library(tidyverse)
library(skimr)
library(caret)
library(caretEnsemble)
library(doParallel)
```

# Load data ------------------

```{r message=FALSE, warning=FALSE}
data <- read_csv("./data/Admission_Predict_Ver1.1.csv")

data <- data %>% mutate(Research = ifelse(Research == 1, T, F))

data$`Serial No.` <- NULL
```

# Data exploration

Over view
```{r}
skim(data)
```

- There is no missing data, and seems to be no outliner. Most of data is numeric, and not skewed. 

Plot

```{r}
plot(data)
```

- A lot of varriable are correlated. Removing correlated predictors is needed

# Parallel processing

```{r}
cl <- makeCluster(16) 
registerDoParallel(cl)
```

# Partition data

```{r}

set.seed(1221)

intrain <- createDataPartition(data$`Chance of Admit`, p = 0.8, list = F)

# Create fold
index <- createMultiFolds(data[intrain,]$`Chance of Admit`, k = 10, times = 5)
trCtr <- trainControl(method = "repeatedcv", repeats = 5, number = 10, index = index, verboseIter = T )
```

## Choose Hyperparameters

```{r, cache = T}

XGBgrid <- expand.grid(nrounds = 100, # Fixed. depend on datasize
                       max_depth = 6, # More will make model more complex and more likely to overfit. Choose only this due to computational barrier
                       eta = c(0.01,0.05, 0.1), # NEED FINE TUNE
                       gamma = 0, # it is usually OK to leave at 0
                       min_child_weight = c(1,2,3), # The higher value, the more conservative model is, NEED FINE TUNE
                       colsample_bytree = c(.4, .7, 1), # subsample by columns
                       subsample = 1) # subsample by row leave at 1 since we doing k-fold

rpartgrid <- expand.grid(cp = runif(30,0,0.5))

rfgrid <- expand.grid(mtry = 1:8)

```


# Modeling

```{r}
data <- data %>% rename("admit" = `Chance of Admit`)
formula <- as.formula(admit~.)


set.seed(12342)

modelList <- caretList(formula,
                       data = data[intrain,], 
                       trControl = trCtr,
                       metric = "RMSE",
                       preProcess = c("pca"), # pca include center and scale
                       tuneList = list(
                         bayesglm = caretModelSpec(method = "bayesglm"),
                         rf=caretModelSpec(method="rf", tuneGrid= rfgrid),
                         SVM=caretModelSpec(method="svmRadial", tuneLength = 10),
                         xgb=caretModelSpec(method="xgbTree", tuneGrid = XGBgrid),
                         rpart= caretModelSpec(method = "rpart", tuneGrid = rpartgrid)
                          )
                       )


```

# Summary

```{r}
dotplot(resamples(modelList))
```

# Diffrence

```{r}
diff(resamples(modelList)) %>% summary()
```

# Correlation models

```{r}
splom(resamples(modelList), metric = "RMSE")
```


# RMSE on test set

```{r}
modelList %>% map_df(~mean((predict(., newdata = data[-intrain,]) - data[-intrain,]$admit)^2))
```

